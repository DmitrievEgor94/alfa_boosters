{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_pickle('/data/edmitrie/alfa_boosters/net_atrs_first_net/part-00009.parquet.pckl')\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# lb_enc.fit(df[df['target'] !='nan']['target'].unique())\n",
    "# lb_enc = LabelEncoder()\n",
    "\n",
    "# lb_enc.fit(df[df['target'] !='nan']['target'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_encoder = pickle.load(open('target_enc_2_net.pickle','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('/data/edmitrie/alfa_boosters/net_atrs_first_net/part-00009.parquet.pckl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_pickle('/data/edmitrie/alfa_boosters/df_atr_1_net.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['target'] != 'nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = lb_encoder.transform(df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timestamp'] = pd.to_datetime(df['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.35 s, sys: 582 ms, total: 6.93 s\n",
      "Wall time: 6.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = df.sort_values(by='timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Формирование валидационной,тестовой,трейн выборок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_cl = df.groupby('client_pin').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use_clnts = pd.Series(gr_cl[gr_cl > 3].index)\n",
    "use_clnts = pd.Series(gr_cl[gr_cl > 2].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_df = df.merge(use_clnts, on='client_pin', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_test_df.groupby('client_pin').apply(lambda x: x.iloc[:-1]).reset_index(drop='True')\n",
    "# valid_df = train_test_df.groupby('client_pin').apply(lambda x: x.iloc[:-1]).reset_index(drop='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_df.sort_values(by='timestamp', inplace=True)\n",
    "train_df.sort_values(by='timestamp', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = train_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.sort_values(by='timestamp', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv('alfabattle2_abattle_train_target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>client_pin</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>multi_class_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000029e72e5fcde6a9f29c3a3ed198f</td>\n",
       "      <td>7cf9221322a0e2fdefb1b998b8f2ab29</td>\n",
       "      <td>2020-06-15 14:01:12</td>\n",
       "      <td>main_screen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00063dffa47b0fe5556b2b9e8beddb6a</td>\n",
       "      <td>5f16c0ab27a806fd08db3122921adf3a</td>\n",
       "      <td>2020-03-21 12:59:34</td>\n",
       "      <td>invest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0007857f36d268ec46fcb7305538a1c7</td>\n",
       "      <td>ec868fc2b388293cf10e18ee9518d72f</td>\n",
       "      <td>2020-01-24 18:18:55</td>\n",
       "      <td>statement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000a7f25fc3609cdfda54c5f059aab00</td>\n",
       "      <td>91f55a33d7502c1a1fa5da7ff2f7b648</td>\n",
       "      <td>2020-03-15 19:50:23</td>\n",
       "      <td>main_screen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000b746d6616669663feaa1474ac97f1</td>\n",
       "      <td>3ef1020bda95ce7836d2680fa553ecb7</td>\n",
       "      <td>2020-02-20 07:56:58</td>\n",
       "      <td>main_screen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         session_id                        client_pin  \\\n",
       "0  0000029e72e5fcde6a9f29c3a3ed198f  7cf9221322a0e2fdefb1b998b8f2ab29   \n",
       "1  00063dffa47b0fe5556b2b9e8beddb6a  5f16c0ab27a806fd08db3122921adf3a   \n",
       "2  0007857f36d268ec46fcb7305538a1c7  ec868fc2b388293cf10e18ee9518d72f   \n",
       "3  000a7f25fc3609cdfda54c5f059aab00  91f55a33d7502c1a1fa5da7ff2f7b648   \n",
       "4  000b746d6616669663feaa1474ac97f1  3ef1020bda95ce7836d2680fa553ecb7   \n",
       "\n",
       "             timestamp multi_class_target  \n",
       "0  2020-06-15 14:01:12        main_screen  \n",
       "1  2020-03-21 12:59:34             invest  \n",
       "2  2020-01-24 18:18:55          statement  \n",
       "3  2020-03-15 19:50:23        main_screen  \n",
       "4  2020-02-20 07:56:58        main_screen  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Формирование сэмплов под нейронку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate(x, num_last_transactions=750):\n",
    "    return x.values.transpose()[:, -num_last_transactions:].tolist()\n",
    "\n",
    "\n",
    "def transform_transactions_to_sequences(transactions_frame: pd.DataFrame,atrs,\n",
    "                                        num_last_transactions=750) -> pd.DataFrame:\n",
    "    return transactions_frame \\\n",
    "        .groupby(['client_pin'])[atrs] \\\n",
    "        .apply(lambda x: truncate(x, num_last_transactions=num_last_transactions)) \\\n",
    "        .reset_index().rename(columns={0: 'sequences'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence(array, max_len) -> np.array:\n",
    "    add_zeros = int(max_len - len(array[0]))\n",
    "    return np.array([list(x) + [0] * add_zeros for x in array])\n",
    "\n",
    "\n",
    "\n",
    "def create_padded_buckets(frame_of_sequences: pd.DataFrame, bucket_info: Dict[int, int],\n",
    "                          save_to_file_path=None, has_target=True):\n",
    "    frame_of_sequences['bucket_idx'] = frame_of_sequences.sequence_length.map(bucket_info)\n",
    "        \n",
    "    \n",
    "#     print(frame_of_sequences.sequence_length.max(), frame_of_sequences.sequence_length.min())\n",
    "        \n",
    "    padded_seq = []\n",
    "    targets = []\n",
    "    lengths = []\n",
    "    client_pin = []\n",
    "    \n",
    "#     print(frame_of_sequences.session_id.unique().shape)\n",
    "#     print(frame_of_sequences.bucket_idx.isnull().sum())\n",
    "\n",
    "    \n",
    "    from tqdm import tqdm\n",
    "\n",
    "    for size, bucket in frame_of_sequences.groupby('bucket_idx'):\n",
    "        padded_sequences = bucket.sequences.apply(lambda x: pad_sequence(x, size)).values\n",
    "        padded_sequences = np.array([np.array(x) for x in padded_sequences])\n",
    "        padded_seq.append(padded_sequences)\n",
    "        \n",
    "        if has_target:\n",
    "            targets.append(bucket.target.values)\n",
    "            \n",
    "#         print(bucket.sequence_length.shape)\n",
    "            \n",
    "        lengths.append(bucket.sequence_length.values)\n",
    "        client_pin.append(bucket.client_pin.values)        \n",
    "    \n",
    "\n",
    "    frame_of_sequences.drop(columns=['bucket_idx'], inplace=True)\n",
    "    \n",
    "    \n",
    "    if has_target:\n",
    "        dict_result = {\n",
    "            'padded_sequences':np.array(padded_seq),\n",
    "            'targets':np.array(targets),\n",
    "            'lengths': np.array(lengths),\n",
    "            'client': np.array(client_pin),\n",
    "        }\n",
    "    else:\n",
    "         dict_result = {\n",
    "            'padded_sequences':np.array(padded_seq),\n",
    "            'lengths': np.array(lengths),\n",
    "            'client': np.array(client_pin),\n",
    "        }\n",
    "\n",
    "    if save_to_file_path:\n",
    "        with open(save_to_file_path, 'wb') as f:\n",
    "            pickle.dump(dict_result, f)\n",
    "    return dict_result\n",
    "\n",
    "\n",
    "def create_buckets_from_transactions(df, file_name, submit=False):   \n",
    "    import tqdm\n",
    "    import os\n",
    "    \n",
    "    train_df = df\n",
    "    \n",
    "    if not submit:\n",
    "        target = df.groupby('client_pin')[['target','session_id', 'timestamp']].last().reset_index()\n",
    "\n",
    "    #     return target\n",
    "\n",
    "        train_df = df.merge(target[['session_id']], on='session_id', how='left', indicator=True)\n",
    "        train_df = train_df[train_df['_merge'] == 'left_only']\n",
    "        \n",
    "        train_df.drop(columns='_merge', inplace=True)\n",
    "        \n",
    "    seq = transform_transactions_to_sequences(train_df, atrs)\n",
    "    seq['sequence_length'] = seq.sequences.apply(lambda x: len(x[1]))\n",
    "    \n",
    "    if not submit:                \n",
    "        seq = seq.merge(target[['client_pin', 'target']], how='left', on='client_pin')\n",
    "    \n",
    "    mapping_seq_len_to_padded_len = pickle.load(open('buckets_info.pkl', 'rb'))\n",
    "    \n",
    "    if not submit:\n",
    "        processed_fragment =  create_padded_buckets(seq, mapping_seq_len_to_padded_len, has_target=True)    \n",
    "    else:\n",
    "        processed_fragment =  create_padded_buckets(seq, mapping_seq_len_to_padded_len, has_target=False)    \n",
    "    res = pd.DataFrame(processed_fragment)\n",
    "    res.to_pickle(file_name)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_net(file_name):\n",
    "    df = pd.read_pickle(file_name)\n",
    "    \n",
    "    df = df[df['target'] != 'nan']\n",
    "    \n",
    "    import pickle\n",
    "    \n",
    "    lb_encoder = pickle.load(open('target_enc_2_net.pickle','rb'))\n",
    "    \n",
    "    df['target'] = lb_encoder.transform( df['target'])\n",
    "    \n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df.sort_values(by='timestamp', inplace=True)\n",
    "    \n",
    "    atrs = [col for col in df.columns if col not in ['client_pin', 'session_id', 'target', 'timestamp']]\n",
    "    \n",
    "    last_name = file_name.split('/')[-1]\n",
    "    \n",
    "    print('приступаю к сабмит файлу')\n",
    "    \n",
    "    create_buckets_from_transactions(df, f'/data/edmitrie/alfa_boosters/net_atrs_2_net/{last_name}_submit', submit=True)\n",
    "    \n",
    "    print('сабмит сохранил')\n",
    "    \n",
    "    gr_cl = df.groupby('client_pin').size()\n",
    "    use_clnts = pd.Series(gr_cl[gr_cl > 2].index)\n",
    "    \n",
    "    train_test_df = df.merge(use_clnts, on='client_pin', how='inner')\n",
    "    \n",
    "    train_df = train_test_df.groupby('client_pin').apply(lambda x: x.iloc[:-1]).reset_index(drop='True')\n",
    "    test_df = df\n",
    "    \n",
    "    train_df.sort_values(by='timestamp', inplace=True)\n",
    "    test_df.sort_values(by='timestamp', inplace=True)\n",
    "\n",
    "    create_buckets_from_transactions(train_df, f'/data/edmitrie/alfa_boosters/net_atrs_2_net/{last_name}_train')\n",
    "    \n",
    "    print('сохранил трейн')\n",
    "    \n",
    "    create_buckets_from_transactions(test_df, f'/data/edmitrie/alfa_boosters/net_atrs_2_net/{last_name}_test')  \n",
    "    print('сохранил тест')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# DIR = '/data/edmitrie/alfa_boosters/net_atrs_first_net'\n",
    "\n",
    "# for file in os.listdir():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 7.39 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get_data_for_net('/data/edmitrie/alfa_boosters/net_atrs_first_net/part-00008.parquet.pckl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:44: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:45: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:46: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:47: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_df_net = create_buckets_from_transactions(test_df, 'chunks_data/processed_test_2_net.pkl')\n",
    "train_df_net = create_buckets_from_transactions(train_df, 'chunks_data/processed_train_2_net.pkl')\n",
    "# valid_df_net = create_buckets_from_transactions(valid_df, 'chunks_data/processed_valid_2_net.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df_net = pd.read_pickle('chunks_data/processed_test_2_net.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Моделирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_net = pd.read_pickle('chunks_data/processed_test_2_net.pkl')\n",
    "train_df_net = pd.read_pickle('chunks_data/processed_train_2_net.pkl')\n",
    "# valid_df_net = pd.read_pickle('chunks_data/processed_valid_2_net.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batches_generator(data,batch_size=32, shuffle=False, is_infinite=False,\n",
    "                      verbose=False, device=None, output_format='torch', is_train=True):\n",
    "    while True:\n",
    "#         if shuffle:\n",
    "#             np.random.shuffle(list_of_paths)\n",
    "\n",
    "#         for path in list_of_paths:\n",
    "#             if verbose:\n",
    "#                 print(f'reading {path}')\n",
    "\n",
    "        padded_sequences, targets, lengths = data['padded_sequences'], data['targets'], data['lengths']\n",
    "\n",
    "        indices = np.arange(len(targets))\n",
    "\n",
    "        if shuffle:\n",
    "            np.random.shuffle(indices)\n",
    "\n",
    "            padded_sequences = padded_sequences[indices]\n",
    "            targets = targets[indices]\n",
    "            lengths = lengths[indices]\n",
    "\n",
    "        for idx in range(len(padded_sequences)):\n",
    "\n",
    "            bucket = padded_sequences[idx]\n",
    "\n",
    "            if is_train:\n",
    "                target = targets[idx]\n",
    "                length = lengths[idx]\n",
    "\n",
    "            for jdx in range(0, len(bucket), batch_size):\n",
    "                batch_sequences = bucket[jdx: jdx + batch_size]\n",
    "#                 print(target.shape)\n",
    "\n",
    "\n",
    "                if is_train:\n",
    "                    batch_targets = target[jdx: jdx + batch_size]\n",
    "                    batch_length = length[jdx: jdx + batch_size]\n",
    "\n",
    "                batch_sequences = torch.FloatTensor(batch_sequences).to(device)\n",
    "\n",
    "                if is_train:\n",
    "                    yield dict(transactions_features=batch_sequences,\n",
    "                               label=torch.LongTensor(batch_targets).to(device),\n",
    "                               lengths=torch.LongTensor(batch_length).to(device)\n",
    "                              )\n",
    "                else:\n",
    "                    yield dict(transactions_features=batch_sequences,\n",
    "                               product=torch.LongTensor(batch_products).to(device),\n",
    "                               lengths=torch.LongTensor(data['lengths']).to(device)\n",
    "                               )\n",
    "        if not is_infinite:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, dataset_train, valid_dataset,  batch_size=64, shuffle=True,\n",
    "                print_loss_every_n_batches=100, device=None):\n",
    "    train_generator = batches_generator(dataset_train, batch_size=batch_size, shuffle=shuffle,\n",
    "                                        device=device, is_train=True, output_format='torch')\n",
    "    \n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    \n",
    "    num_batches = 1\n",
    "    running_loss = 0.0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(train_generator):\n",
    "        \n",
    "        output = model(batch['transactions_features'], batch['lengths'])\n",
    "#         print(output.shape)\n",
    "#         print(batch['label'].shape)\n",
    "        batch_loss = loss_function(output, batch['label'])\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "#             val_generator = batches_generator(dataset_valid, atrs, batch_size=batch_size, shuffle=False,\n",
    "#                                       device=device, is_train=True, output_format='torch')\n",
    "            model_os = []\n",
    "            targets_l = []\n",
    "                        \n",
    "            for (seqs, targets, lengths) in zip(valid_dataset['padded_sequences'], valid_dataset['targets'], valid_dataset['lengths']):\n",
    "                batch_sequences = torch.FloatTensor(seqs).to(device)\n",
    "                lengths = torch.LongTensor(lengths).to(device)\n",
    "    \n",
    "                logits = model(batch_sequences, lengths)\n",
    "    \n",
    "                model_os.append(logits.argmax(axis=-1).detach().cpu().numpy().flatten())\n",
    "                targets_l.append(targets)\n",
    "#                 print(np.unique(logits.argmax(axis=-1).detach().cpu().numpy().flatten()))\n",
    "\n",
    "            print(f1_score(np.concatenate(model_os), np.concatenate(targets_l), average='macro'))\n",
    "            \n",
    "#             for batch_t in val_generator:\n",
    "                \n",
    "#                 _, output = model(batch_t['transactions_features'], batch_t['lengths'])\n",
    "#                 metrics.append(f1_score(batch_t['label'].detach().cpu().numpy().flatten(), output.argmax(axis=-1).detach().cpu().numpy().flatten(), average='macro'))\n",
    "                \n",
    "#             print(np.mean(metrics))\n",
    "#             print(metrics)\n",
    "\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        running_loss += batch_loss\n",
    "\n",
    "        if num_batches % print_loss_every_n_batches == 0:\n",
    "            print(f'Training loss after {num_batches} batches: {running_loss / num_batches}', end='\\r')\n",
    "        \n",
    "        num_batches += 1\n",
    "    \n",
    "    print(f'Training loss after epoch: {running_loss / num_batches}', end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class TransactionsRnn(nn.Module):\n",
    "    def __init__(self,  rnn_units=300, top_classifier_units=32, classes=11):\n",
    "        super(TransactionsRnn, self).__init__()\n",
    "                                \n",
    "        self._gru = nn.GRU(input_size=128, num_layers=1,\n",
    "                             hidden_size=rnn_units, batch_first=True, bidirectional=False)\n",
    "        \n",
    "        self._hidden_size = rnn_units\n",
    "                \n",
    "        self._top_classifier = nn.Linear(in_features=rnn_units, \n",
    "                                         out_features=top_classifier_units)\n",
    "        \n",
    "        self._intermediate_activation = nn.ReLU()\n",
    "        \n",
    "        self._head = nn.Linear(in_features=top_classifier_units, out_features=classes)\n",
    "        \n",
    "    \n",
    "    def forward(self, input_t, lengths): \n",
    "        input_t = input_t.permute(0, 2, 1)\n",
    "#         print(input_t.shape)\n",
    "        \n",
    "        packed_inputs = torch.nn.utils.rnn.pack_padded_sequence(input_t, lengths, batch_first=True, enforce_sorted=False)\n",
    "            \n",
    "        _, final_hiddens = self._gru(packed_inputs)\n",
    "                \n",
    "        final_hiddens = final_hiddens.view(input_t.size(0),-1)\n",
    "                                           \n",
    "        classification_hidden = self._top_classifier(final_hiddens)\n",
    "        activation = self._intermediate_activation(classification_hidden)\n",
    "        \n",
    "        logits = self._head(activation)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransactionsRnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(lr=1e-3, params=model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "train_batch_size = 128\n",
    "val_batch_szie = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "0.03052272418217149\n",
      "0.23391162965607165\n",
      "Starting epoch 2ter epoch: 1.481927514076233\n",
      "0.266917537032637\n",
      "0.27965360138248346\n",
      "Starting epoch 3ter epoch: 1.2918602228164673\n",
      "0.2829478642854447\n",
      "0.30109129297267917\n",
      "Starting epoch 4ter epoch: 1.2184216976165771\n",
      "0.30170555708838076\n",
      "0.3171363832866937\n",
      "Starting epoch 5ter epoch: 1.1636524200439453\n",
      "0.29427722573154996\n",
      "0.31837939531937265\n",
      "Starting epoch 6ter epoch: 1.1147105693817139\n",
      "0.28998297194848\n",
      "0.3204360582718024\n",
      "Starting epoch 7ter epoch: 1.0595520734786987\n",
      "0.3256090741811337\n",
      "0.3354545160271575\n",
      "Starting epoch 8ter epoch: 1.0106464624404907\n",
      "0.3243756554030078\n",
      "0.3337535216814425\n",
      "Starting epoch 9ter epoch: 0.9533373713493347\n",
      "0.33353563075616127\n",
      "0.32673296621276954\n",
      "Starting epoch 10er epoch: 0.9087492823600769\n",
      "0.34568485285135975\n",
      "0.3133815329727134\n",
      "Starting epoch 11er epoch: 0.8563689589500427\n",
      "0.3621976665229255\n",
      "0.30455785774012617\n",
      "Starting epoch 12er epoch: 0.8023719787597656\n",
      "0.3568100524766362\n",
      "0.29765976865984495\n",
      "Starting epoch 13er epoch: 0.7525460720062256\n",
      "0.35154575930009385\n",
      "0.3123056555210234\n",
      "Starting epoch 14er epoch: 0.7035342454910278\n",
      "0.3600804295130769\n",
      "0.31581680384384697\n",
      "Starting epoch 15er epoch: 0.6520922183990479\n",
      "0.3556381352102231\n",
      "0.3142693655561425\n",
      "Starting epoch 16er epoch: 0.6140242218971252\n",
      "0.35037812595808127\n",
      "0.25770543786970185\n",
      "Starting epoch 17er epoch: 0.5948238372802734\n",
      "0.29998289824229596\n",
      "0.3201574183466545\n",
      "Starting epoch 18er epoch: 0.6141076683998108\n",
      "0.3503475195372415\n",
      "0.33608263418923195\n",
      "Starting epoch 19er epoch: 0.6078270077705383\n",
      "0.3258241934103227\n",
      "0.3437269308976559\n",
      "Starting epoch 20er epoch: 0.5115002393722534\n",
      "0.2502551774386731\n",
      "0.3449350922012722\n",
      "Starting epoch 21er epoch: 0.5044779181480408\n",
      "0.3497747869440597\n",
      "0.3244285661607736\n",
      "Starting epoch 22er epoch: 0.4194186329841614\n",
      "0.34962184400841523\n",
      "0.3113337483054803\n",
      "Starting epoch 23er epoch: 0.3630082607269287\n",
      "0.3440966018027328\n",
      "0.3033963838821743\n",
      "Starting epoch 24er epoch: 0.31475183367729187\n",
      "0.31451312519662944\n",
      "0.31287953398789053\n",
      "Starting epoch 25er epoch: 0.2737221121788025\n",
      "0.3236913434367327\n",
      "0.292662741032617\n",
      "Starting epoch 26er epoch: 0.25473979115486145\n",
      "0.33641703977077614\n",
      "0.31711272941337076\n",
      "Starting epoch 27er epoch: 0.3685106039047241\n",
      "0.3296370149385303\n",
      "0.28512768543489136\n",
      "Starting epoch 28er epoch: 0.30086666345596313\n",
      "0.2575004181620929\n",
      "0.32145836678976175\n",
      "Starting epoch 29er epoch: 0.4713538885116577\n",
      "0.3260380071319678\n",
      "0.35939871423940634\n",
      "Starting epoch 30er epoch: 0.26964235305786133\n",
      "0.35857727572048914\n",
      "0.3570330305933919\n",
      "Starting epoch 31er epoch: 0.19546082615852356\n",
      "0.3521682921573833\n",
      "0.3569335575523131\n",
      "Starting epoch 32er epoch: 0.15543696284294128\n",
      "0.35373219736441813\n",
      "0.3494613476546579\n",
      "Starting epoch 33er epoch: 0.13183563947677612\n",
      "0.3492180470332509\n",
      "0.3488842556362496\n",
      "Starting epoch 34er epoch: 0.11209811270236969\n",
      "0.33591180393705455\n",
      "0.35885422445415593\n",
      "Starting epoch 35er epoch: 0.09831222146749496\n",
      "0.3582346631873553\n",
      "0.3544623949707539\n",
      "Starting epoch 36er epoch: 0.08600489050149918\n",
      "0.35624564236451584\n",
      "0.28924166310973\n",
      "Starting epoch 37er epoch: 0.25872907042503357\n",
      "0.2980835709889595\n",
      "0.3292348893924146\n",
      "Starting epoch 38er epoch: 0.923379123210907\n",
      "0.30567309932331577\n",
      "0.34542823251199317\n",
      "Starting epoch 39er epoch: 0.6715403199195862\n",
      "0.3281171206633837\n",
      "0.3521969107808781\n",
      "Starting epoch 40er epoch: 0.42302370071411133\n",
      "0.3519721610345464\n",
      "0.3539892664479095\n",
      "Starting epoch 41er epoch: 0.2941080927848816\n",
      "0.35590633835086827\n",
      "0.3522439517591023\n",
      "Starting epoch 42er epoch: 0.21651028096675873\n",
      "0.35370908364302217\n",
      "0.34717215103960053\n",
      "Starting epoch 43er epoch: 0.16499999165534973\n",
      "0.34829546134260775\n",
      "0.33923212275305586\n",
      "Starting epoch 44er epoch: 0.130177840590477\n",
      "0.3385381281835698\n",
      "0.3464158879593383\n",
      "Starting epoch 45er epoch: 0.1039908155798912\n",
      "0.34561534072289585\n",
      "0.3487941562308058\n",
      "Starting epoch 46er epoch: 0.0852394700050354\n",
      "0.3474321255408431\n",
      "0.3571281227245279\n",
      "Starting epoch 47er epoch: 0.07139486074447632\n",
      "0.3572401287483439\n",
      "0.36245230468632655\n",
      "Starting epoch 48er epoch: 0.06090198829770088\n",
      "0.3622544986464602\n",
      "0.35796549176463227\n",
      "Starting epoch 49er epoch: 0.05298254266381264\n",
      "0.3582611510889339\n",
      "0.3573151823840585\n",
      "Starting epoch 50er epoch: 0.0471029058098793\n",
      "0.357056394343252\n",
      "0.35513169821197627\n",
      "Starting epoch 51er epoch: 0.042585067451000214\n",
      "0.3546019620151107\n",
      "0.35904649586363674\n",
      "Starting epoch 52er epoch: 0.040374644100666046\n",
      "0.35898662259383984\n",
      "0.31522517497898284\n",
      "Starting epoch 53er epoch: 0.2780067026615143\n",
      "0.27261971539431595\n",
      "0.2995324945989289\n",
      "Starting epoch 54er epoch: 0.9623395204544067\n",
      "0.3082584576293111\n",
      "0.33102711808118646\n",
      "Starting epoch 55er epoch: 0.627203643321991\n",
      "0.3314320003116299\n",
      "0.34888759776902023\n",
      "Starting epoch 56er epoch: 0.39507484436035156\n",
      "0.3538012356351682\n",
      "0.34702012004178223\n",
      "Starting epoch 57er epoch: 0.26494377851486206\n",
      "0.34869313563897675\n",
      "0.34782900330735733\n",
      "Starting epoch 58er epoch: 0.17728999257087708\n",
      "0.3479891156914865\n",
      "0.35284879878315484\n",
      "Starting epoch 59er epoch: 0.1227780431509018\n",
      "0.3523968377175699\n",
      "0.3461724396638099\n",
      "Starting epoch 60er epoch: 0.08935824781656265\n",
      "0.34623828309330446\n",
      "0.3510237630541724\n",
      "Starting epoch 61er epoch: 0.06732548773288727\n",
      "0.3504629289255633\n",
      "0.359561113017539\n",
      "Starting epoch 62er epoch: 0.05287996307015419\n",
      "0.359812048067153\n",
      "0.36386469125189114\n",
      "Starting epoch 63er epoch: 0.0440143346786499\n",
      "0.3646334058163278\n",
      "0.3636752687989081\n",
      "Starting epoch 64er epoch: 0.036385826766490936\n",
      "0.36355423899583567\n",
      "0.36531982948799824\n",
      "Starting epoch 65er epoch: 0.03218083828687668\n",
      "0.3652904080106443\n",
      "0.36057593962907347\n",
      "Starting epoch 66er epoch: 0.029933759942650795\n",
      "0.36029971585290266\n",
      "0.3600352045354075\n",
      "Starting epoch 67er epoch: 0.027382811531424522\n",
      "0.36061124408173606\n",
      "0.34327193013098667\n",
      "Starting epoch 68er epoch: 0.03241778910160065\n",
      "0.29526432495535754\n",
      "0.3207970994339495\n",
      "Starting epoch 69er epoch: 0.2918425500392914\n",
      "0.2878176460408157\n",
      "0.33636134594469935\n",
      "Starting epoch 70er epoch: 0.22167761623859406\n",
      "0.33776524819606746\n",
      "0.34884622216941363\n",
      "Starting epoch 71er epoch: 0.10949613898992538\n",
      "0.3510001935467069\n",
      "0.3491842625199827\n",
      "Starting epoch 72er epoch: 0.05644923448562622\n",
      "0.3478240239629889\n",
      "0.36062648651859247\n",
      "Starting epoch 73er epoch: 0.03350616991519928\n",
      "0.3602975467205321\n",
      "0.36010098630498566\n",
      "Starting epoch 74er epoch: 0.023570338264107704\n",
      "0.36021641379770974\n",
      "0.35897688007109163\n",
      "Starting epoch 75er epoch: 0.019649052992463112\n",
      "0.35899255517842377\n",
      "0.36276803826418536\n",
      "Starting epoch 76er epoch: 0.018087051808834076\n",
      "0.36283387133021944\n",
      "0.35951752327272557\n",
      "Starting epoch 77er epoch: 0.01613754779100418\n",
      "0.35951752327272557\n",
      "0.3602584478503159\n",
      "Starting epoch 78er epoch: 0.014702647924423218\n",
      "0.3599619572309681\n",
      "0.36061946628313657\n",
      "Starting epoch 79er epoch: 0.013440370559692383\n",
      "0.3605029926104185\n",
      "0.36080906939174895\n",
      "Starting epoch 80er epoch: 0.01269935816526413\n",
      "0.36083302951463536\n",
      "0.36220546996473163\n",
      "Starting epoch 81er epoch: 0.012011931277811527\n",
      "0.36220546996473163\n",
      "0.36169786948989874\n",
      "Starting epoch 82er epoch: 0.011147537268698215\n",
      "0.3618050887482368\n",
      "0.3629166561190813\n",
      "Starting epoch 83er epoch: 0.010527582839131355\n",
      "0.3629166561190813\n",
      "0.36251746583756045\n",
      "Starting epoch 84er epoch: 0.010058744810521603\n",
      "0.36251746583756045\n",
      "0.3628601131384218\n",
      "Starting epoch 85er epoch: 0.009560472331941128\n",
      "0.3627695324916326\n",
      "0.36082178295314293\n",
      "Starting epoch 86er epoch: 0.00942073855549097\n",
      "0.36082178295314293\n",
      "0.3631716990515581\n",
      "Starting epoch 87er epoch: 0.009181330911815166\n",
      "0.3631716990515581\n",
      "0.35908957109704515\n",
      "Starting epoch 88er epoch: 0.009763761423528194\n",
      "0.35908957109704515\n",
      "0.35676793518789196\n",
      "Starting epoch 89er epoch: 0.13308799266815186\n",
      "0.2974553230959074\n",
      "0.29255876393478164\n",
      "Starting epoch 90er epoch: 0.9310742616653442\n",
      "0.2651001871178588\n",
      "0.3349132072086011\n",
      "Starting epoch 91er epoch: 0.5340979695320129\n",
      "0.316587703355109\n",
      "0.32142355955854646\n",
      "Starting epoch 92er epoch: 0.38513419032096863\n",
      "0.298055871905206\n",
      "0.3396582321331875\n",
      "Starting epoch 93er epoch: 0.21973295509815216\n",
      "0.33892521376320084\n",
      "0.34652117491671697\n",
      "Starting epoch 94er epoch: 0.12768882513046265\n",
      "0.3468065084724442\n",
      "0.3460774903235281\n",
      "Starting epoch 95er epoch: 0.07824528217315674\n",
      "0.3454613046283689\n",
      "0.3504912893883769\n",
      "Starting epoch 96er epoch: 0.05293133109807968\n",
      "0.3498347389213808\n",
      "0.3525386244532731\n",
      "Starting epoch 97er epoch: 0.03885732591152191\n",
      "0.35268488629498035\n",
      "0.3563069809511993\n",
      "Starting epoch 98er epoch: 0.03060021996498108\n",
      "0.3568375924106569\n",
      "0.35709706527878426\n",
      "Starting epoch 99er epoch: 0.02499457262456417\n",
      "0.3568806749342197\n",
      "0.3534099667568265\n",
      "Starting epoch 100r epoch: 0.02084067277610302\n",
      "0.35337242484968484\n",
      "0.35373641009131307\n",
      "Starting epoch 101r epoch: 0.018032610416412354\n",
      "0.35443425270362117\n",
      "0.3544878991112019\n",
      "Starting epoch 102r epoch: 0.015792671591043472\n",
      "0.3544878991112019\n",
      "0.3547580321582781\n",
      "Starting epoch 103r epoch: 0.014072681777179241\n",
      "0.3543601497023865\n",
      "0.3562523536290168\n",
      "Starting epoch 104r epoch: 0.012683795765042305\n",
      "0.3562523536290168\n",
      "0.35629069977822236\n",
      "Starting epoch 105r epoch: 0.011595780029892921\n",
      "0.35629069977822236\n",
      "0.3576267179315598\n",
      "Starting epoch 106r epoch: 0.010677890852093697\n",
      "0.35759050784500945\n",
      "0.357848685639196\n",
      "Starting epoch 107r epoch: 0.009922495111823082\n",
      "0.35814821631843863\n",
      "0.35918720059243\n",
      "Starting epoch 108r epoch: 0.009218841791152954\n",
      "0.3597786443918783\n",
      "0.3595620883651387\n",
      "Starting epoch 109r epoch: 0.00860859639942646\n",
      "0.3596473776272616\n",
      "0.35995678611895937\n",
      "Starting epoch 110r epoch: 0.008065194822847843\n",
      "0.3602054103212141\n",
      "0.3597324678091103\n",
      "Starting epoch 111r epoch: 0.007586178835481405\n",
      "0.3597324678091103\n",
      "0.3616718735507952\n",
      "Starting epoch 112r epoch: 0.007230738177895546\n",
      "0.3619660580566391\n",
      "0.3581716474618931\n",
      "Starting epoch 113r epoch: 0.006905764807015657\n",
      "0.3581046715944443\n",
      "0.36159782358810383\n",
      "Starting epoch 114r epoch: 0.006833985447883606\n",
      "0.36159782358810383\n",
      "0.3590214020315524\n",
      "Starting epoch 115r epoch: 0.006960335187613964\n",
      "0.3590214020315524\n",
      "0.35191861747949676\n",
      "Starting epoch 116r epoch: 0.008798590861260891\n",
      "0.3517814729409531\n",
      "0.28632668174327447\n",
      "Starting epoch 117r epoch: 0.42351269721984863\n",
      "0.27368111103560905\n",
      "0.3153836284125989\n",
      "Starting epoch 118r epoch: 1.0848444700241089\n",
      "0.29734747302518627\n",
      "0.33759772378403186\n",
      "Starting epoch 119r epoch: 0.7131243944168091\n",
      "0.3253675480031043\n",
      "0.32864749110287733\n",
      "Starting epoch 120r epoch: 0.5096503496170044\n",
      "0.32989552787382387\n",
      "0.3371765358839344\n",
      "Starting epoch 121r epoch: 0.3636568486690521\n",
      "0.336315396237736\n",
      "0.33805976112161185\n",
      "Starting epoch 122r epoch: 0.26188182830810547\n",
      "0.3379714524167511\n",
      "0.3452648175383319\n",
      "Starting epoch 123r epoch: 0.19066527485847473\n",
      "0.34631429840953587\n",
      "0.3480410043362045\n",
      "Starting epoch 124r epoch: 0.1374213695526123\n",
      "0.3483519787647241\n",
      "0.34626545667737424\n",
      "Starting epoch 125r epoch: 0.099761001765728\n",
      "0.3464267857380682\n",
      "0.34906390441509566\n",
      "Starting epoch 126r epoch: 0.07353655993938446\n",
      "0.3488619427309489\n",
      "0.3521658813184825\n",
      "Starting epoch 127r epoch: 0.05454200133681297\n",
      "0.35227557693046846\n",
      "0.35460642461759556\n",
      "Starting epoch 128r epoch: 0.04180363938212395\n",
      "0.354190336853925\n",
      "0.35454535373558554\n",
      "Starting epoch 129r epoch: 0.03304719179868698\n",
      "0.35475866526132205\n",
      "0.35632818426255497\n",
      "Starting epoch 130r epoch: 0.02710244432091713\n",
      "0.3561607977928083\n",
      "0.35590158199303756\n",
      "Starting epoch 131r epoch: 0.022721758112311363\n",
      "0.355938380337001\n",
      "0.30053794290164404\n",
      "Starting epoch 132r epoch: 0.028431974351406097\n",
      "0.3371809487931114\n",
      "0.33053931670574016\n",
      "Starting epoch 133r epoch: 0.2679210305213928\n",
      "0.329140265693065\n",
      "0.34066756993030617\n",
      "Starting epoch 134r epoch: 0.17812086641788483\n",
      "0.33747584204632053\n",
      "0.3530192598819875\n",
      "Starting epoch 135r epoch: 0.08051775395870209\n",
      "0.35340980611507217\n",
      "0.3402368099760714\n",
      "Starting epoch 136r epoch: 0.045677851885557175\n",
      "0.3396615198735601\n",
      "0.3505294597525707\n",
      "Starting epoch 137r epoch: 0.049242280423641205\n",
      "0.3501697891499797\n",
      "0.3528254224890647\n",
      "Starting epoch 138r epoch: 0.02749720774590969\n",
      "0.3527314020192954\n",
      "0.3562710710328155\n",
      "Starting epoch 139r epoch: 0.016411418095231056\n",
      "0.356118892774741\n",
      "0.3562328834098482\n",
      "Starting epoch 140r epoch: 0.011325592175126076\n",
      "0.3568125476700305\n",
      "0.3572485111280118\n",
      "Starting epoch 141r epoch: 0.00959473755210638\n",
      "0.35723126207871797\n",
      "0.3591620488623629\n",
      "Starting epoch 142r epoch: 0.008660156279802322\n",
      "0.3591620488623629\n",
      "0.359735605159195\n",
      "Starting epoch 143r epoch: 0.007797833997756243\n",
      "0.35964722247136427\n",
      "0.35922152607566094\n",
      "Starting epoch 144r epoch: 0.007132495753467083\n",
      "0.3592680471313835\n",
      "0.3603548830867791\n",
      "Starting epoch 145r epoch: 0.006647957023233175\n",
      "0.3603548830867791\n",
      "0.360524773364069\n",
      "Starting epoch 146r epoch: 0.006234962493181229\n",
      "0.3605352195532839\n",
      "0.3604253967549886\n",
      "Starting epoch 147r epoch: 0.005924091208726168\n",
      "0.3604616288697665\n",
      "0.36027997921984484\n",
      "Starting epoch 148r epoch: 0.005632468499243259\n",
      "0.36027997921984484\n",
      "0.3611859741684599\n",
      "Starting epoch 149r epoch: 0.005381900351494551\n",
      "0.3610080184118215\n",
      "0.35993844659525603\n",
      "Starting epoch 150r epoch: 0.005339381285011768\n",
      "0.35993844659525603\n",
      "0.36036197126753444\n",
      "Starting epoch 151r epoch: 0.0053558796644210815\n",
      "0.36037598675684734\n",
      "0.35933223773018486\n",
      "Starting epoch 152r epoch: 0.005562694743275642\n",
      "0.35933223773018486\n",
      "0.3570702870904752\n",
      "Starting epoch 153r epoch: 0.007663064636290073\n",
      "0.35717293714499365\n",
      "0.3547499833392711\n",
      "Starting epoch 154r epoch: 0.007370127364993095\n",
      "0.35449918812837916\n",
      "0.35717648887514664\n",
      "Starting epoch 155r epoch: 0.007988031022250652\n",
      "0.3571020273196626\n",
      "0.35850662976537373\n",
      "Starting epoch 156r epoch: 0.007367040030658245\n",
      "0.3585735207885121\n",
      "0.2911161141815333\n",
      "Starting epoch 157r epoch: 0.38746336102485657\n",
      "0.20856470203463404\n",
      "0.28994579562945666\n",
      "Starting epoch 158r epoch: 1.4354679584503174\n",
      "0.28992247962291223\n",
      "0.31355735949758523\n",
      "Starting epoch 159r epoch: 0.7318211197853088\n",
      "0.31163872129368825\n",
      "0.3377294763896056\n",
      "Starting epoch 160r epoch: 0.5403873324394226\n",
      "0.33160146469330687\n",
      "0.34486065031471286\n",
      "Starting epoch 161r epoch: 0.425834059715271\n",
      "0.34336294142551277\n",
      "0.34242077675307814\n",
      "Starting epoch 162r epoch: 0.34459933638572693\n",
      "0.343307751136501\n",
      "0.3469541493488912\n",
      "Starting epoch 163r epoch: 0.28010886907577515\n",
      "0.34714387752167175\n",
      "0.348317476112636\n",
      "Starting epoch 164r epoch: 0.22747358679771423\n",
      "0.3485282154238374\n",
      "0.3513288932830507\n",
      "Starting epoch 165r epoch: 0.18282228708267212\n",
      "0.35092161118834514\n",
      "0.35181357248263645\n",
      "Starting epoch 166r epoch: 0.14521948993206024\n",
      "0.3499493471694454\n",
      "0.3529163642300538\n",
      "Starting epoch 167r epoch: 0.11476978659629822\n",
      "0.3502519206641086\n",
      "0.35393515873747955\n",
      "Starting epoch 168r epoch: 0.08940014243125916\n",
      "0.353536765760526\n",
      "0.3557949643950186\n",
      "Starting epoch 169r epoch: 0.0694374367594719\n",
      "0.35592678366196095\n",
      "0.3566684489224861\n",
      "Starting epoch 170r epoch: 0.053726114332675934\n",
      "0.3567065399511774\n",
      "0.3562669365287855\n",
      "Starting epoch 171r epoch: 0.042190954089164734\n",
      "0.3563743288723672\n",
      "0.3574861955272591\n",
      "Starting epoch 172r epoch: 0.03326303884387016\n",
      "0.3567946414681082\n",
      "0.3574074579505211\n",
      "Starting epoch 173r epoch: 0.026469185948371887\n",
      "0.3568600569677762\n",
      "0.356599341947577\n",
      "Starting epoch 174r epoch: 0.021619385108351707\n",
      "0.35672737672333277\n",
      "0.3552282231097605\n",
      "Starting epoch 175r epoch: 0.01776163838803768\n",
      "0.35502742670590454\n",
      "0.3572165173623011\n",
      "Starting epoch 176r epoch: 0.01487458311021328\n",
      "0.3571514334919891\n",
      "0.35747503361379546\n",
      "Starting epoch 177r epoch: 0.012681452557444572\n",
      "0.3573125652290416\n",
      "0.3574143742248216\n",
      "Starting epoch 178r epoch: 0.011061872355639935\n",
      "0.35739187443705633\n",
      "0.3542171564647533\n",
      "Starting epoch 179r epoch: 0.00975401233881712\n",
      "0.3541178427510553\n",
      "0.3564790217327977\n",
      "Starting epoch 180r epoch: 0.008594948798418045\n",
      "0.3563942794462609\n",
      "0.35700492819454704\n",
      "Starting epoch 181r epoch: 0.007768869865685701\n",
      "0.3568213576487399\n",
      "0.3580925170370508\n",
      "Starting epoch 182r epoch: 0.007046871818602085\n",
      "0.35786250691720706\n",
      "0.35780691149943916\n",
      "Starting epoch 183r epoch: 0.006445202976465225\n",
      "0.35787503946537125\n",
      "0.3577124278590355\n",
      "Starting epoch 184r epoch: 0.005941274110227823\n",
      "0.357507497912796\n",
      "0.3577853412851101\n",
      "Starting epoch 185r epoch: 0.0055217985063791275\n",
      "0.35785101437871425\n",
      "0.35759624440506343\n",
      "Starting epoch 186r epoch: 0.005108230281621218\n",
      "0.3576825070766931\n",
      "0.35791360702531677\n",
      "Starting epoch 187r epoch: 0.004850497003644705\n",
      "0.3576731009335761\n",
      "0.3589386134273119\n",
      "Starting epoch 188r epoch: 0.004577388521283865\n",
      "0.35892399786806567\n",
      "0.3568734524699272\n",
      "Starting epoch 189r epoch: 0.004383904859423637\n",
      "0.3571160025258157\n",
      "0.3574630007768457\n",
      "Starting epoch 190r epoch: 0.004221660550683737\n",
      "0.3579831090558785\n",
      "0.35622348636357515\n",
      "Starting epoch 191r epoch: 0.004239074885845184\n",
      "0.3562668508568969\n",
      "0.3580475149155593\n",
      "Starting epoch 192r epoch: 0.004196644760668278\n",
      "0.3580475149155593\n",
      "0.3572309700326558\n",
      "Starting epoch 193r epoch: 0.004252141807228327\n",
      "0.3572309700326558\n",
      "0.36027160992536045\n",
      "Starting epoch 194r epoch: 0.004208773840218782\n",
      "0.3604649423233625\n",
      "0.36008264860660627\n",
      "Starting epoch 195r epoch: 0.004017801955342293\n",
      "0.3600046296070713\n",
      "0.3603670704856918\n",
      "Starting epoch 196r epoch: 0.003904270939528942\n",
      "0.36071742227591547\n",
      "0.25581032113448626\n",
      "Starting epoch 197r epoch: 0.5554840564727783\n",
      "0.2591787323231138\n",
      "0.314619729774925\n",
      "Starting epoch 198r epoch: 1.2393591403961182\n",
      "0.3134490978181267\n",
      "0.31582352672441105\n",
      "Starting epoch 199r epoch: 0.7928542494773865\n",
      "0.3192459072064103\n",
      "0.3316624328189829\n",
      "Starting epoch 200r epoch: 0.5773512721061707\n",
      "0.3305540543619188\n",
      "0.33131844290896173\n",
      "Training loss after epoch: 0.4588985741138458\r"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f'Starting epoch {epoch+1}')\n",
    "    \n",
    "    train_epoch(model, optimizer, train_df_net, test_df_net,  batch_size=train_batch_size, \n",
    "                shuffle=True, print_loss_every_n_batches=500, device=device)\n",
    "    \n",
    "#     val_roc_auc = eval_model(model, dataset_val, batch_size=val_batch_szie, device=device)\n",
    "#     es(val_roc_auc, model)\n",
    "\n",
    "#     if es.early_stop:\n",
    "#         print('Early stopping reached. Stop training...')\n",
    "#         break\n",
    "#     torch.save(model.state_dict(), os.path.join(path_to_checkpoints, f'epoch_{epoch+1}_val_{val_roc_auc:.3f}.pt'))\n",
    "    \n",
    "#     train_roc_auc = eval_model(model, dataset_train, batch_size=val_batch_szie, device=device)\n",
    "#     print(f'Epoch {epoch+1} completed. Train roc-auc: {train_roc_auc}, Val roc-auc: {val_roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransactionsRnn(\n",
       "  (_gru): GRU(128, 200, batch_first=True)\n",
       "  (_top_classifier): Linear(in_features=200, out_features=32, bias=True)\n",
       "  (_intermediate_activation): ReLU()\n",
       "  (_head): Linear(in_features=32, out_features=11, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_os = []\n",
    "targets_l = []\n",
    "\n",
    "for sequnces, targets, lengths in zip(test_df_net['padded_sequences'], test_df_net['targets'], test_df_net['lengths']):\n",
    "    batch_sequences = torch.FloatTensor(sequnces).to(device)\n",
    "    lengths = torch.LongTensor(lengths).to(device)\n",
    "    \n",
    "    logits = model(batch_sequences, lengths)\n",
    "    \n",
    "    model_os.append(logits.argmax(axis=-1).detach().cpu().numpy().flatten())\n",
    "    targets_l.append(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = np.concatenate(model_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = np.concatenate(targets_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edmitrie/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>260.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.438849</td>\n",
       "      <td>0.204698</td>\n",
       "      <td>0.279176</td>\n",
       "      <td>298.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.028796</td>\n",
       "      <td>0.053790</td>\n",
       "      <td>382.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.557258</td>\n",
       "      <td>0.679449</td>\n",
       "      <td>0.612317</td>\n",
       "      <td>1017.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.588089</td>\n",
       "      <td>0.809034</td>\n",
       "      <td>0.681091</td>\n",
       "      <td>3210.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.058140</td>\n",
       "      <td>0.104987</td>\n",
       "      <td>344.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.455696</td>\n",
       "      <td>0.437690</td>\n",
       "      <td>316.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.340741</td>\n",
       "      <td>0.224939</td>\n",
       "      <td>0.270987</td>\n",
       "      <td>409.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.455310</td>\n",
       "      <td>0.372633</td>\n",
       "      <td>0.409844</td>\n",
       "      <td>1162.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.544686</td>\n",
       "      <td>0.544686</td>\n",
       "      <td>0.544686</td>\n",
       "      <td>0.544686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.408258</td>\n",
       "      <td>0.287185</td>\n",
       "      <td>0.291885</td>\n",
       "      <td>7452.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.511943</td>\n",
       "      <td>0.544686</td>\n",
       "      <td>0.495464</td>\n",
       "      <td>7452.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "0              0.333333  0.038462  0.068966   260.000000\n",
       "1              0.438849  0.204698  0.279176   298.000000\n",
       "2              0.407407  0.028796  0.053790   382.000000\n",
       "3              0.557258  0.679449  0.612317  1017.000000\n",
       "4              0.000000  0.000000  0.000000    54.000000\n",
       "5              0.588089  0.809034  0.681091  3210.000000\n",
       "6              0.540541  0.058140  0.104987   344.000000\n",
       "8              0.421053  0.455696  0.437690   316.000000\n",
       "9              0.340741  0.224939  0.270987   409.000000\n",
       "10             0.455310  0.372633  0.409844  1162.000000\n",
       "accuracy       0.544686  0.544686  0.544686     0.544686\n",
       "macro avg      0.408258  0.287185  0.291885  7452.000000\n",
       "weighted avg   0.511943  0.544686  0.495464  7452.000000"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(classification_report(targets, outputs, output_dict=True)).T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python36",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
